[Server]
host = localhost
port = 7777
url = http://%(host)s:%(port)s/inference

[Models]
# Directory containing the whisper.cpp model files (.bin)
# Must be set via WHISPER_MODELS_DIR environment variable
default_model = ggml-tiny.en.bin

[Recording]
# Minimum recording duration in seconds
min_duration = 0.1
# Sample rate for audio recording
sample_rate = 16000

[Defaults]
language = en
auto_copy = false
auto_type = false
show_audio_meter = false
translate = false

[Server Command]
# Command to start the whisper.cpp server
# Available placeholders: {model_path}, {language}, {port}
command = whisper-server -m {model_path} -l {language} --port {port} 