[Server]
host = localhost
port = 7777
url = http://%(host)s:%(port)s/inference
# Command to start the whisper.cpp server
# Available placeholders: {model_path}, {language}, {port}
command = whisper-server -m {model_path} -l {language} --port {port} 

[Models]
# Directory containing the whisper.cpp model files (.bin)
models_dir = ${HOME}/.local/share/whisper-models
default_model = ggml-tiny.en.bin

[Paths]
# Virtual environment path
venv_path = ${HOME}/.venvs/whispertype

[Recording]
# Minimum recording duration in seconds
min_duration = 0.1
# Sample rate for audio recording
sample_rate = 16000

[Defaults]
language = en
auto_copy = false
auto_type = false
show_audio_meter = false
translate = false
verbose = false

[UI]
# Icon theme - light or dark
theme = light
# Notification sound when recording starts/stops
enable_sounds = true
